#!/bin/bash

# RAG Assistant App Startup Script

echo "üöÄ Starting RAG Assistant App..."

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "‚ùå Docker is not running. Please start Docker first."
    exit 1
fi

# Check if .env file exists
if [ ! -f .env ]; then
    echo "üìù Creating .env file from template..."
    cp env.example .env
    echo "‚ö†Ô∏è  Please edit .env file and add your OpenAI API key before continuing."
    echo "   You can also use local models by setting USE_LOCAL_LLM=true"
    read -p "Press Enter to continue after editing .env file..."
fi

# Create necessary directories
echo "üìÅ Creating directories..."
mkdir -p uploads
mkdir -p qdrant_data
mkdir -p redis_data

# Start services
echo "üê≥ Starting Docker services..."
docker-compose up -d

# Wait for services to be healthy
echo "‚è≥ Waiting for services to start..."
sleep 10

# Check service health
echo "üîç Checking service health..."

# Check Qdrant
if curl -f http://localhost:6333/health > /dev/null 2>&1; then
    echo "‚úÖ Qdrant is healthy"
else
    echo "‚ùå Qdrant is not responding"
fi

# Check Redis
if docker exec rag_redis redis-cli ping > /dev/null 2>&1; then
    echo "‚úÖ Redis is healthy"
else
    echo "‚ùå Redis is not responding"
fi

# Check API
if curl -f http://localhost:8000/v1/health > /dev/null 2>&1; then
    echo "‚úÖ API is healthy"
else
    echo "‚ùå API is not responding"
fi

# Check UI
if curl -f http://localhost:8501/_stcore/health > /dev/null 2>&1; then
    echo "‚úÖ UI is healthy"
else
    echo "‚ùå UI is not responding"
fi

echo ""
echo "üéâ RAG Assistant App is starting up!"
echo ""
echo "üì± Access the application:"
echo "   ‚Ä¢ Streamlit UI: http://localhost:8501"
echo "   ‚Ä¢ API Docs: http://localhost:8000/docs"
echo "   ‚Ä¢ Qdrant Dashboard: http://localhost:6333/dashboard"
echo ""
echo "üìã Useful commands:"
echo "   ‚Ä¢ View logs: docker-compose logs -f"
echo "   ‚Ä¢ Stop services: docker-compose down"
echo "   ‚Ä¢ Restart services: docker-compose restart"
echo ""
echo "üîß To use local models (optional):"
echo "   ‚Ä¢ Start Ollama: docker-compose --profile local-llm up -d"
echo "   ‚Ä¢ Pull model: docker exec rag_ollama ollama pull llama3.1:8b"
echo "   ‚Ä¢ Update .env: USE_LOCAL_LLM=true"
echo ""
